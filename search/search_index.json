{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is swarm-cronjob? \u00b6 swarm-cronjob creates jobs on a time-based schedule on Swarm with a dedicated service in a distributed manner that configures itself automatically and dynamically through labels and Docker API. Features \u00b6 Continuously updates its configuration (no restart) Cron implementation through go routines Allow to skip a job if the service is currently running Timezone can be changed for the scheduler License \u00b6 This project is licensed under the terms of the MIT license. Icon credit to Laurel .","title":"Home"},{"location":"#what-is-swarm-cronjob","text":"swarm-cronjob creates jobs on a time-based schedule on Swarm with a dedicated service in a distributed manner that configures itself automatically and dynamically through labels and Docker API.","title":"What is swarm-cronjob?"},{"location":"#features","text":"Continuously updates its configuration (no restart) Cron implementation through go routines Allow to skip a job if the service is currently running Timezone can be changed for the scheduler","title":"Features"},{"location":"#license","text":"This project is licensed under the terms of the MIT license. Icon credit to Laurel .","title":"License"},{"location":"changelog/","text":"Changelog \u00b6 1.14.0 (2024/12/24) \u00b6 Add tzdata package to Docker image (#337) Go 1.23 (#372) Alpine Linux 3.21 (#372) Bump github.com/alecthomas/kong from 0.8.1 to 1.6.0 (#325 #374) Bump github.com/distribution/reference to 0.6.0 (#373) Bump github.com/docker/cli to 27.4.1+incompatible (#378) Bump github.com/docker/docker to 27.4.1+incompatible (#378) Bump github.com/rs/zerolog to 1.33.0 (#320 #345) Bump golang.org/x/sys from 0.16.0 to 0.28.0 (#333 #346 #375) 1.13.0 (2024/02/01) \u00b6 Enables automatic API version negotiation for the docker client (#313) Go 1.21 (#285 #284) Alpine Linux 3.19 (#317) Bump github.com/alecthomas/kong to 0.8.1 (#289) Bump github.com/distribution/distribution to 2.8.3+incompatible (#259 #260 #302) Bump github.com/docker/cli to 24.0.7+incompatible (#250 #290) Bump github.com/docker/docker to 24.0.7+incompatible (#250 #290) Bump github.com/opencontainers/image-spec to 1.0.2 (#239) Bump github.com/prometheus/client_golang to 1.11.1 (#234) Bump github.com/rs/zerolog from 1.29.0 to 1.31.0 (#245 #288) Bump golang.org/x/crypto to 0.17.0 (#237 #303) Bump golang.org/x/net to 0.17.0 (#238 #287) Bump golang.org/x/sys to 0.16.0 (#252 #279 #301 #306) 1.12.0 (2023/02/14) \u00b6 Go 1.19 (#214) Alpine Linux 3.17 (#223) Enhance workflow (#215) Bump github.com/alecthomas/kong from 0.6.1 to 0.7.1 (#220) Bump github.com/docker/cli from 20.10.17+incompatible to 20.10.22+incompatible (#221) Bump github.com/docker/docker from 20.10.17+incompatible to 20.10.22+incompatible (#222) Bump golang.org/x/sys to 0.5.0 (#224 #230) Bump github.com/rs/zerolog from 1.27.0 to 1.29.0 (#207 #227) Bump github.com/docker/distribution from 2.7.1+incompatible to 2.8.0+incompatible (#233) 1.11.0 (2022/07/17) \u00b6 Option to query the registry on service update (#201) Fix possible nil pointer with ElectAuthServer from docker cli (#202) Go 1.18 (#204) Alpine Linux 3.16 (#166 #206) goreleaser-xx 1.2.5 Move syscall to golang.org/x/sys MkDocs Material 8.3.9 (#205) Enhance dockerfiles (#163) Bump github.com/alecthomas/kong from 0.2.17 to 0.6.1 (#152 #162 #165 #176 #200) Bump github.com/docker/cli from 20.10.8 to 20.10.17 (#149 #160 #197) Bump github.com/docker/docker from 20.10.8 to 20.10.17 (#148 #159 #196) Bump github.com/mitchellh/mapstructure from 1.4.1 to 1.5.0 (#145 #155 #181) Bump github.com/rs/zerolog from 1.24.0 to 1.27.0 (#144 #150 #162 #198) 1.10.0 (2021/09/05) \u00b6 Docker client v20.10.8 (#109 #110 #134 #135) Go 1.17 (#114 #140) Add darwin/amd64 , darwin/arm64 , linux/riscv64 , windows/arm64 artifacts (#141) Alpine Linux 3.14 MkDocs Materials 7.2.6 (#143) Remove linux/s390x Docker platform support (for now) Switch to goreleaser-xx (#111) Bump github.com/rs/zerolog from 1.20.0 to 1.24.0 (#131 #137 #142) Bump github.com/mitchellh/mapstructure from 1.4.0 to 1.4.1 (#103) Bump github.com/alecthomas/kong from 0.2.12 to 0.2.16 (#106 #112) 1.9.0 (2021/01/03) \u00b6 Refactor CI and dev workflow with buildx bake (#99) Upload artifacts Add image-local target Single job for artifacts and image Add armv5 artifact Use embedded tzdata package and remove --timezone flag (#98) Go 1.15 (#97) Send registry authentication details to Swarm agents (#96) Docker client v20.10.1 Remove support for freebsd/* (moby/moby#38818) Handle registry auth from spec (#92) Bump github.com/mitchellh/mapstructure from 1.3.3 to 1.4.0 (#88) Bump github.com/alecthomas/kong from 0.2.11 to 0.2.12 (#89) Docker image also available on GitHub Container Registry Bump github.com/rs/zerolog from 1.19.0 to 1.20.0 (#68) Docs website with mkdocs Switch to Docker actions Add notes about timezone (#43) Add renovate example (#42) Add MariaDB dump example (#35) 1.8.0 (2020/04/06) \u00b6 Switch to kong command-line parser Go 1.13 Docker client v19.03.8 Use Open Container Specification labels as label-schema.org ones are deprecated Update deps 1.7.1 (2019/11/11) \u00b6 Update deps Cache go modules 1.7.0 (2019/10/30) \u00b6 Seconds field is now optional Docker client v19.03.4 1.6.0 (2019/10/13) \u00b6 Allow to set more replicas (#16) Docker client v19.03.3 Update deps 1.5.0 (2019/09/27) \u00b6 Update deps Go 1.12.10 1.4.0 (2019/09/22) \u00b6 Log removed/disabled services Docker client v19.03.2 Use GOPROXY Stop publishing Docker image on Quay Multi-platform Docker image Switch to GitHub Actions Add instructions to create a Linux service 1.3.0 (2019/07/19) \u00b6 Docker client v18.09.8 1.3.0-beta.1 (2019/07/18) \u00b6 Add support for global mode (#7) Use v3 robfig/cron Docker client v18.09.7 1.2.1 (2019/05/30) \u00b6 Fix nil pointer (#7) 1.2.0 (2019/05/01) \u00b6 Skip completed tasks while checking status (#4) Update Docker client and some libs Go 1.12.4 1.1.0 (2019/03/21) \u00b6 Go 1.12.1 1.0.0 (2019/02/17) \u00b6 Add JSON log output Deliver artifacts through goreleaser Review project structure 0.2.1 (2019/01/24) \u00b6 Go 1.11.5 Update go.sum after go@1.11.4 symlink fix (golang/go#29278) 0.2.0 (2019/01/22) \u00b6 Add support for Docker API 1.38 (#3) ldflags -X not properly applied 0.1.2 (2019/01/14) \u00b6 Fix non-cronjob services added to cronjob list (#2) Handle removed services NPE while checking service 0.1.1 (2018/12/13) \u00b6 Fix build args Checksum mismatch on Go 1.11.4 0.1.0 (2018/12/13) \u00b6 Initial version based on Docker API 1.26","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#1140-20241224","text":"Add tzdata package to Docker image (#337) Go 1.23 (#372) Alpine Linux 3.21 (#372) Bump github.com/alecthomas/kong from 0.8.1 to 1.6.0 (#325 #374) Bump github.com/distribution/reference to 0.6.0 (#373) Bump github.com/docker/cli to 27.4.1+incompatible (#378) Bump github.com/docker/docker to 27.4.1+incompatible (#378) Bump github.com/rs/zerolog to 1.33.0 (#320 #345) Bump golang.org/x/sys from 0.16.0 to 0.28.0 (#333 #346 #375)","title":"1.14.0 (2024/12/24)"},{"location":"changelog/#1130-20240201","text":"Enables automatic API version negotiation for the docker client (#313) Go 1.21 (#285 #284) Alpine Linux 3.19 (#317) Bump github.com/alecthomas/kong to 0.8.1 (#289) Bump github.com/distribution/distribution to 2.8.3+incompatible (#259 #260 #302) Bump github.com/docker/cli to 24.0.7+incompatible (#250 #290) Bump github.com/docker/docker to 24.0.7+incompatible (#250 #290) Bump github.com/opencontainers/image-spec to 1.0.2 (#239) Bump github.com/prometheus/client_golang to 1.11.1 (#234) Bump github.com/rs/zerolog from 1.29.0 to 1.31.0 (#245 #288) Bump golang.org/x/crypto to 0.17.0 (#237 #303) Bump golang.org/x/net to 0.17.0 (#238 #287) Bump golang.org/x/sys to 0.16.0 (#252 #279 #301 #306)","title":"1.13.0 (2024/02/01)"},{"location":"changelog/#1120-20230214","text":"Go 1.19 (#214) Alpine Linux 3.17 (#223) Enhance workflow (#215) Bump github.com/alecthomas/kong from 0.6.1 to 0.7.1 (#220) Bump github.com/docker/cli from 20.10.17+incompatible to 20.10.22+incompatible (#221) Bump github.com/docker/docker from 20.10.17+incompatible to 20.10.22+incompatible (#222) Bump golang.org/x/sys to 0.5.0 (#224 #230) Bump github.com/rs/zerolog from 1.27.0 to 1.29.0 (#207 #227) Bump github.com/docker/distribution from 2.7.1+incompatible to 2.8.0+incompatible (#233)","title":"1.12.0 (2023/02/14)"},{"location":"changelog/#1110-20220717","text":"Option to query the registry on service update (#201) Fix possible nil pointer with ElectAuthServer from docker cli (#202) Go 1.18 (#204) Alpine Linux 3.16 (#166 #206) goreleaser-xx 1.2.5 Move syscall to golang.org/x/sys MkDocs Material 8.3.9 (#205) Enhance dockerfiles (#163) Bump github.com/alecthomas/kong from 0.2.17 to 0.6.1 (#152 #162 #165 #176 #200) Bump github.com/docker/cli from 20.10.8 to 20.10.17 (#149 #160 #197) Bump github.com/docker/docker from 20.10.8 to 20.10.17 (#148 #159 #196) Bump github.com/mitchellh/mapstructure from 1.4.1 to 1.5.0 (#145 #155 #181) Bump github.com/rs/zerolog from 1.24.0 to 1.27.0 (#144 #150 #162 #198)","title":"1.11.0 (2022/07/17)"},{"location":"changelog/#1100-20210905","text":"Docker client v20.10.8 (#109 #110 #134 #135) Go 1.17 (#114 #140) Add darwin/amd64 , darwin/arm64 , linux/riscv64 , windows/arm64 artifacts (#141) Alpine Linux 3.14 MkDocs Materials 7.2.6 (#143) Remove linux/s390x Docker platform support (for now) Switch to goreleaser-xx (#111) Bump github.com/rs/zerolog from 1.20.0 to 1.24.0 (#131 #137 #142) Bump github.com/mitchellh/mapstructure from 1.4.0 to 1.4.1 (#103) Bump github.com/alecthomas/kong from 0.2.12 to 0.2.16 (#106 #112)","title":"1.10.0 (2021/09/05)"},{"location":"changelog/#190-20210103","text":"Refactor CI and dev workflow with buildx bake (#99) Upload artifacts Add image-local target Single job for artifacts and image Add armv5 artifact Use embedded tzdata package and remove --timezone flag (#98) Go 1.15 (#97) Send registry authentication details to Swarm agents (#96) Docker client v20.10.1 Remove support for freebsd/* (moby/moby#38818) Handle registry auth from spec (#92) Bump github.com/mitchellh/mapstructure from 1.3.3 to 1.4.0 (#88) Bump github.com/alecthomas/kong from 0.2.11 to 0.2.12 (#89) Docker image also available on GitHub Container Registry Bump github.com/rs/zerolog from 1.19.0 to 1.20.0 (#68) Docs website with mkdocs Switch to Docker actions Add notes about timezone (#43) Add renovate example (#42) Add MariaDB dump example (#35)","title":"1.9.0 (2021/01/03)"},{"location":"changelog/#180-20200406","text":"Switch to kong command-line parser Go 1.13 Docker client v19.03.8 Use Open Container Specification labels as label-schema.org ones are deprecated Update deps","title":"1.8.0 (2020/04/06)"},{"location":"changelog/#171-20191111","text":"Update deps Cache go modules","title":"1.7.1 (2019/11/11)"},{"location":"changelog/#170-20191030","text":"Seconds field is now optional Docker client v19.03.4","title":"1.7.0 (2019/10/30)"},{"location":"changelog/#160-20191013","text":"Allow to set more replicas (#16) Docker client v19.03.3 Update deps","title":"1.6.0 (2019/10/13)"},{"location":"changelog/#150-20190927","text":"Update deps Go 1.12.10","title":"1.5.0 (2019/09/27)"},{"location":"changelog/#140-20190922","text":"Log removed/disabled services Docker client v19.03.2 Use GOPROXY Stop publishing Docker image on Quay Multi-platform Docker image Switch to GitHub Actions Add instructions to create a Linux service","title":"1.4.0 (2019/09/22)"},{"location":"changelog/#130-20190719","text":"Docker client v18.09.8","title":"1.3.0 (2019/07/19)"},{"location":"changelog/#130-beta1-20190718","text":"Add support for global mode (#7) Use v3 robfig/cron Docker client v18.09.7","title":"1.3.0-beta.1 (2019/07/18)"},{"location":"changelog/#121-20190530","text":"Fix nil pointer (#7)","title":"1.2.1 (2019/05/30)"},{"location":"changelog/#120-20190501","text":"Skip completed tasks while checking status (#4) Update Docker client and some libs Go 1.12.4","title":"1.2.0 (2019/05/01)"},{"location":"changelog/#110-20190321","text":"Go 1.12.1","title":"1.1.0 (2019/03/21)"},{"location":"changelog/#100-20190217","text":"Add JSON log output Deliver artifacts through goreleaser Review project structure","title":"1.0.0 (2019/02/17)"},{"location":"changelog/#021-20190124","text":"Go 1.11.5 Update go.sum after go@1.11.4 symlink fix (golang/go#29278)","title":"0.2.1 (2019/01/24)"},{"location":"changelog/#020-20190122","text":"Add support for Docker API 1.38 (#3) ldflags -X not properly applied","title":"0.2.0 (2019/01/22)"},{"location":"changelog/#012-20190114","text":"Fix non-cronjob services added to cronjob list (#2) Handle removed services NPE while checking service","title":"0.1.2 (2019/01/14)"},{"location":"changelog/#011-20181213","text":"Fix build args Checksum mismatch on Go 1.11.4","title":"0.1.1 (2018/12/13)"},{"location":"changelog/#010-20181213","text":"Initial version based on Docker API 1.26","title":"0.1.0 (2018/12/13)"},{"location":"contributing/","text":"Contributing \u00b6 Hi there! I'm thrilled that you'd like to contribute to this project. Your help is essential for keeping it great. Contributions to this project are released to the public under the project's open source license . Submitting a pull request \u00b6 Fork and clone the repository Configure and install the dependencies: go mod download Create a new branch: git checkout -b my-branch-name Make your changes Validate: docker buildx bake validate Build the project: docker buildx bake artifact-all image-all Push to your fork and submit a pull request Pat your self on the back and wait for your pull request to be reviewed and merged. Here are a few things you can do that will increase the likelihood of your pull request being accepted: Make sure the README.md and any other relevant documentation are kept up-to-date . I try to follow SemVer v2.0.0 . Randomly breaking public APIs is not an option. Keep your change as focused as possible. If there are multiple changes you would like to make that are not dependent upon each other, consider submitting them as separate pull requests . Write a good commit message . Resources \u00b6 How to Contribute to Open Source Using Pull Requests GitHub Help","title":"Contributing"},{"location":"contributing/#contributing","text":"Hi there! I'm thrilled that you'd like to contribute to this project. Your help is essential for keeping it great. Contributions to this project are released to the public under the project's open source license .","title":"Contributing"},{"location":"contributing/#submitting-a-pull-request","text":"Fork and clone the repository Configure and install the dependencies: go mod download Create a new branch: git checkout -b my-branch-name Make your changes Validate: docker buildx bake validate Build the project: docker buildx bake artifact-all image-all Push to your fork and submit a pull request Pat your self on the back and wait for your pull request to be reviewed and merged. Here are a few things you can do that will increase the likelihood of your pull request being accepted: Make sure the README.md and any other relevant documentation are kept up-to-date . I try to follow SemVer v2.0.0 . Randomly breaking public APIs is not an option. Keep your change as focused as possible. If there are multiple changes you would like to make that are not dependent upon each other, consider submitting them as separate pull requests . Write a good commit message .","title":"Submitting a pull request"},{"location":"contributing/#resources","text":"How to Contribute to Open Source Using Pull Requests GitHub Help","title":"Resources"},{"location":"donate/","text":"swarm-cronjob is free and open source and always will be. All kinds of contributions are welcome! The most basic way to show your support is to star the project , or to raise issues. You can also support this project by becoming a sponsor on GitHub or by making a Paypal donation to ensure this journey continues indefinitely!","title":"Donate"},{"location":"faq/","text":"FAQ \u00b6 Timezones \u00b6 By default, all interpretation and scheduling is done with your local timezone ( TZ environment variable). Individual cron schedules may also override the time zone they are to be interpreted in by providing an additional space-separated field at the beginning of the cron spec, of the form CRON_TZ=Asia/Tokyo . For example: version : \"3.2\" services : test : image : busybox command : date deploy : mode : replicated replicas : 0 labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=CRON_TZ=Asia/Tokyo * * * * *\" - \"swarm.cronjob.skip-running=false\" restart_policy : condition : none","title":"FAQ"},{"location":"faq/#faq","text":"","title":"FAQ"},{"location":"faq/#timezones","text":"By default, all interpretation and scheduling is done with your local timezone ( TZ environment variable). Individual cron schedules may also override the time zone they are to be interpreted in by providing an additional space-separated field at the beginning of the cron spec, of the form CRON_TZ=Asia/Tokyo . For example: version : \"3.2\" services : test : image : busybox command : date deploy : mode : replicated replicas : 0 labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=CRON_TZ=Asia/Tokyo * * * * *\" - \"swarm.cronjob.skip-running=false\" restart_policy : condition : none","title":"Timezones"},{"location":"reporting-issue/","text":"Reporting an issue \u00b6 Before submitting an issue \u00b6 First, be a good guy . Please do a search in open issues to see if the issue or feature request has already been filed. If you find your issue already exists, make relevant comments and add your reaction . Use a reaction in place of a \"+1\" comment. - upvote - downvote If you cannot find an existing issue that describes your bug or feature, submit an issue using the guidelines below. Writing good bug reports and feature requests \u00b6 File a single issue per problem and feature request. Do not enumerate multiple bugs or feature requests in the same issue. Do not add your issue as a comment to an existing issue unless it's for the identical input. Many issues look similar, but have different causes. The more information you can provide, the more likely someone will be successful reproducing the issue and finding a fix. You are now ready to create a new issue ! Closure policy \u00b6 Issues that don't have the information requested above (when applicable) will be closed immediately and the poster directed to the support guidelines. Issues that go a week without a response from original poster are subject to closure at our discretion.","title":"Reporting an issue"},{"location":"reporting-issue/#reporting-an-issue","text":"","title":"Reporting an issue"},{"location":"reporting-issue/#before-submitting-an-issue","text":"First, be a good guy . Please do a search in open issues to see if the issue or feature request has already been filed. If you find your issue already exists, make relevant comments and add your reaction . Use a reaction in place of a \"+1\" comment. - upvote - downvote If you cannot find an existing issue that describes your bug or feature, submit an issue using the guidelines below.","title":"Before submitting an issue"},{"location":"reporting-issue/#writing-good-bug-reports-and-feature-requests","text":"File a single issue per problem and feature request. Do not enumerate multiple bugs or feature requests in the same issue. Do not add your issue as a comment to an existing issue unless it's for the identical input. Many issues look similar, but have different causes. The more information you can provide, the more likely someone will be successful reproducing the issue and finding a fix. You are now ready to create a new issue !","title":"Writing good bug reports and feature requests"},{"location":"reporting-issue/#closure-policy","text":"Issues that don't have the information requested above (when applicable) will be closed immediately and the poster directed to the support guidelines. Issues that go a week without a response from original poster are subject to closure at our discretion.","title":"Closure policy"},{"location":"examples/dump-mariadb/","text":"Dump MariaDB database \u00b6 version : \"3.2\" services : db : image : mariadb:10.4 environment : - \"MYSQL_ROOT_PASSWORD=sup\" - \"MYSQL_DATABASE=foo\" - \"MYSQL_USER=foo\" - \"MYSQL_PASSWORD=bar\" volumes : - \"db:/var/lib/mysql\" dump : image : mariadb:10.4 command : bash -c \"mkdir -p /dumps && /usr/bin/mysqldump -v -h db -u root --password=sup foo | gzip -9 > /dumps/backup-$$(date +%Y%m%d-%H%M%S).sql.gz && ls -al /dumps/\" depends_on : - db volumes : - \"dumps:/dumps\" deploy : labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=* * * * *\" - \"swarm.cronjob.skip-running=true\" replicas : 0 restart_policy : condition : none volumes : db : dumps :","title":"Dump MariaDB database"},{"location":"examples/dump-mariadb/#dump-mariadb-database","text":"version : \"3.2\" services : db : image : mariadb:10.4 environment : - \"MYSQL_ROOT_PASSWORD=sup\" - \"MYSQL_DATABASE=foo\" - \"MYSQL_USER=foo\" - \"MYSQL_PASSWORD=bar\" volumes : - \"db:/var/lib/mysql\" dump : image : mariadb:10.4 command : bash -c \"mkdir -p /dumps && /usr/bin/mysqldump -v -h db -u root --password=sup foo | gzip -9 > /dumps/backup-$$(date +%Y%m%d-%H%M%S).sql.gz && ls -al /dumps/\" depends_on : - db volumes : - \"dumps:/dumps\" deploy : labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=* * * * *\" - \"swarm.cronjob.skip-running=true\" replicas : 0 restart_policy : condition : none volumes : db : dumps :","title":"Dump MariaDB database"},{"location":"examples/prune-swarm-nodes/","text":"Prune Swarm nodes \u00b6 version : \"3.2\" services : prune-nodes : image : docker command : [ \"docker\" , \"system\" , \"prune\" , \"-f\" ] volumes : - \"/var/run/docker.sock:/var/run/docker.sock\" deploy : mode : global labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=0 */5 * * * *\" - \"swarm.cronjob.skip-running=false\" restart_policy : condition : none","title":"Prune Swarm nodes"},{"location":"examples/prune-swarm-nodes/#prune-swarm-nodes","text":"version : \"3.2\" services : prune-nodes : image : docker command : [ \"docker\" , \"system\" , \"prune\" , \"-f\" ] volumes : - \"/var/run/docker.sock:/var/run/docker.sock\" deploy : mode : global labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=0 */5 * * * *\" - \"swarm.cronjob.skip-running=false\" restart_policy : condition : none","title":"Prune Swarm nodes"},{"location":"examples/renovate/","text":"Renovate \u00b6 version : \"3.8\" services : renovate : image : \"renovate/renovate:slim\" configs : - source : config-js-prod-v1 target : /usr/src/app/config.js secrets : - api-token-v1 healthcheck : disable : true volumes : - \"/var/run/docker.sock:/var/run/docker.sock\" deploy : mode : replicated replicas : 0 labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=*/30 * * * *\" restart_policy : condition : none configs : config-js-prod-v1 : file : configs/prod/config.js.tmpl template_driver : golang secrets : api-token-v1 : external : true","title":"Renovate"},{"location":"examples/renovate/#renovate","text":"version : \"3.8\" services : renovate : image : \"renovate/renovate:slim\" configs : - source : config-js-prod-v1 target : /usr/src/app/config.js secrets : - api-token-v1 healthcheck : disable : true volumes : - \"/var/run/docker.sock:/var/run/docker.sock\" deploy : mode : replicated replicas : 0 labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=*/30 * * * *\" restart_policy : condition : none configs : config-js-prod-v1 : file : configs/prod/config.js.tmpl template_driver : golang secrets : api-token-v1 : external : true","title":"Renovate"},{"location":"install/binary/","text":"Installation from binary \u00b6 Download \u00b6 swarm-cronjob binaries are available on releases page. Choose the archive matching the destination platform: swarm-cronjob_1.14.0_darwin_amd64.tar.gz swarm-cronjob_1.14.0_darwin_arm64.tar.gz swarm-cronjob_1.14.0_linux_386.tar.gz swarm-cronjob_1.14.0_linux_amd64.tar.gz swarm-cronjob_1.14.0_linux_arm64.tar.gz swarm-cronjob_1.14.0_linux_armv5.tar.gz swarm-cronjob_1.14.0_linux_armv6.tar.gz swarm-cronjob_1.14.0_linux_armv7.tar.gz swarm-cronjob_1.14.0_linux_ppc64le.tar.gz swarm-cronjob_1.14.0_linux_riscv64.tar.gz swarm-cronjob_1.14.0_linux_s390x.tar.gz swarm-cronjob_1.14.0_windows_386.zip swarm-cronjob_1.14.0_windows_amd64.zip swarm-cronjob_1.14.0_windows_arm64.zip And extract swarm-cronjob: wget -qO- https://github.com/crazy-max/swarm-cronjobreleases/download/v1.14.0/swarm-cronjob_1.14.0_linux_x86_64.tar.gz | tar -zxvf - swarm-cronjob After getting the binary, it can be tested with ./swarm-cronjob --help command and moved to a permanent location. Server configuration \u00b6 Steps below are the recommended server configuration. Prepare environment \u00b6 Create user to run swarm-cronjob (ex. swarm-cronjob ) groupadd swarm-cronjob useradd -s /bin/false -d /bin/null -g swarm-cronjob swarm-cronjob Copy binary to global location \u00b6 cp swarm-cronjob /usr/local/bin/swarm-cronjob Running swarm-cronjob \u00b6 After the above steps, two options to run swarm-cronjob: 1. Creating a service file (recommended) \u00b6 See how to create Linux service to start swarm-cronjob automatically. 2. Running from terminal \u00b6 /usr/local/bin/swarm-cronjob Note When launched manually, swarm-cronjob can be killed using Ctrl+C Updating to a new version \u00b6 You can update to a new version of swarm-cronjob by stopping it, replacing the binary at /usr/local/bin/swarm-cronjob and restarting the instance. If you have carried out the installation steps as described above, the binary should have the generic name swarm-cronjob . Do not change this, i.e. to include the version number.","title":"From binary"},{"location":"install/binary/#installation-from-binary","text":"","title":"Installation from binary"},{"location":"install/binary/#download","text":"swarm-cronjob binaries are available on releases page. Choose the archive matching the destination platform: swarm-cronjob_1.14.0_darwin_amd64.tar.gz swarm-cronjob_1.14.0_darwin_arm64.tar.gz swarm-cronjob_1.14.0_linux_386.tar.gz swarm-cronjob_1.14.0_linux_amd64.tar.gz swarm-cronjob_1.14.0_linux_arm64.tar.gz swarm-cronjob_1.14.0_linux_armv5.tar.gz swarm-cronjob_1.14.0_linux_armv6.tar.gz swarm-cronjob_1.14.0_linux_armv7.tar.gz swarm-cronjob_1.14.0_linux_ppc64le.tar.gz swarm-cronjob_1.14.0_linux_riscv64.tar.gz swarm-cronjob_1.14.0_linux_s390x.tar.gz swarm-cronjob_1.14.0_windows_386.zip swarm-cronjob_1.14.0_windows_amd64.zip swarm-cronjob_1.14.0_windows_arm64.zip And extract swarm-cronjob: wget -qO- https://github.com/crazy-max/swarm-cronjobreleases/download/v1.14.0/swarm-cronjob_1.14.0_linux_x86_64.tar.gz | tar -zxvf - swarm-cronjob After getting the binary, it can be tested with ./swarm-cronjob --help command and moved to a permanent location.","title":"Download"},{"location":"install/binary/#server-configuration","text":"Steps below are the recommended server configuration.","title":"Server configuration"},{"location":"install/binary/#prepare-environment","text":"Create user to run swarm-cronjob (ex. swarm-cronjob ) groupadd swarm-cronjob useradd -s /bin/false -d /bin/null -g swarm-cronjob swarm-cronjob","title":"Prepare environment"},{"location":"install/binary/#copy-binary-to-global-location","text":"cp swarm-cronjob /usr/local/bin/swarm-cronjob","title":"Copy binary to global location"},{"location":"install/binary/#running-swarm-cronjob","text":"After the above steps, two options to run swarm-cronjob:","title":"Running swarm-cronjob"},{"location":"install/binary/#1-creating-a-service-file-recommended","text":"See how to create Linux service to start swarm-cronjob automatically.","title":"1. Creating a service file (recommended)"},{"location":"install/binary/#2-running-from-terminal","text":"/usr/local/bin/swarm-cronjob Note When launched manually, swarm-cronjob can be killed using Ctrl+C","title":"2. Running from terminal"},{"location":"install/binary/#updating-to-a-new-version","text":"You can update to a new version of swarm-cronjob by stopping it, replacing the binary at /usr/local/bin/swarm-cronjob and restarting the instance. If you have carried out the installation steps as described above, the binary should have the generic name swarm-cronjob . Do not change this, i.e. to include the version number.","title":"Updating to a new version"},{"location":"install/docker/","text":"Installation with Docker \u00b6 About \u00b6 swarm-cronjob provides automatically updated Docker images within several registries: Registry Image Docker Hub crazymax/swarm-cronjob GitHub Container Registry ghcr.io/crazy-max/swarm-cronjob It is possible to always use the latest stable tag or to use another service that handles updating Docker images. Note Want to be notified of new releases? Check out Diun (Docker Image Update Notifier) project! Following platforms for this image are available: $ docker run --rm mplatform/mquery crazymax/swarm-cronjob:latest Image: crazymax/swarm-cronjob:latest * Manifest List: Yes * Supported platforms: - linux/amd64 - linux/arm/v6 - linux/arm/v7 - linux/arm64 - linux/386 - linux/ppc64le Usage \u00b6 version : \"3.2\" services : swarm-cronjob : image : crazymax/swarm-cronjob volumes : - \"/var/run/docker.sock:/var/run/docker.sock\" environment : - \"TZ=Europe/Paris\" - \"LOG_LEVEL=info\" - \"LOG_JSON=false\" deploy : placement : constraints : - node.role == manager Edit this example with your preferences and deploy the stack: docker stack deploy -c swarm_cronjob.yml swarm_cronjob Or use the following command: docker service create --name swarm_cronjob \\ --mount type = bind,source = /var/run/docker.sock,target = /var/run/docker.sock \\ --env \"LOG_LEVEL=info\" \\ --env \"LOG_JSON=false\" \\ --constraint \"node.role == manager\" \\ crazymax/swarm-cronjob You are now ready to deploy cronjob based services with swarm .","title":"With Docker"},{"location":"install/docker/#installation-with-docker","text":"","title":"Installation with Docker"},{"location":"install/docker/#about","text":"swarm-cronjob provides automatically updated Docker images within several registries: Registry Image Docker Hub crazymax/swarm-cronjob GitHub Container Registry ghcr.io/crazy-max/swarm-cronjob It is possible to always use the latest stable tag or to use another service that handles updating Docker images. Note Want to be notified of new releases? Check out Diun (Docker Image Update Notifier) project! Following platforms for this image are available: $ docker run --rm mplatform/mquery crazymax/swarm-cronjob:latest Image: crazymax/swarm-cronjob:latest * Manifest List: Yes * Supported platforms: - linux/amd64 - linux/arm/v6 - linux/arm/v7 - linux/arm64 - linux/386 - linux/ppc64le","title":"About"},{"location":"install/docker/#usage","text":"version : \"3.2\" services : swarm-cronjob : image : crazymax/swarm-cronjob volumes : - \"/var/run/docker.sock:/var/run/docker.sock\" environment : - \"TZ=Europe/Paris\" - \"LOG_LEVEL=info\" - \"LOG_JSON=false\" deploy : placement : constraints : - node.role == manager Edit this example with your preferences and deploy the stack: docker stack deploy -c swarm_cronjob.yml swarm_cronjob Or use the following command: docker service create --name swarm_cronjob \\ --mount type = bind,source = /var/run/docker.sock,target = /var/run/docker.sock \\ --env \"LOG_LEVEL=info\" \\ --env \"LOG_JSON=false\" \\ --constraint \"node.role == manager\" \\ crazymax/swarm-cronjob You are now ready to deploy cronjob based services with swarm .","title":"Usage"},{"location":"install/linux-service/","text":"Run as service on Debian based distro \u00b6 Using systemd \u00b6 Warning Make sure to follow the instructions to install from binary before. To create a new service, paste this content in /etc/systemd/system/swarm-cronjob.service : [Unit] Description=swarm-cronjob Documentation=https://crazymax.dev/swarm-cronjob/ After=syslog.target After=network.target [Service] RestartSec=2s Type=simple User=swarmcronjob Group=swarmcronjob ExecStart=/usr/local/bin/swarm-cronjob Restart=always #Environment=TZ=Europe/Paris [Install] WantedBy=multi-user.target Change the user, group, and other required startup values following your needs. Enable and start swarm-cronjob at boot: sudo systemctl enable swarm-cronjob sudo systemctl start swarm-cronjob To view logs: journalctl -fu swarm-cronjob.service","title":"Linux service"},{"location":"install/linux-service/#run-as-service-on-debian-based-distro","text":"","title":"Run as service on Debian based distro"},{"location":"install/linux-service/#using-systemd","text":"Warning Make sure to follow the instructions to install from binary before. To create a new service, paste this content in /etc/systemd/system/swarm-cronjob.service : [Unit] Description=swarm-cronjob Documentation=https://crazymax.dev/swarm-cronjob/ After=syslog.target After=network.target [Service] RestartSec=2s Type=simple User=swarmcronjob Group=swarmcronjob ExecStart=/usr/local/bin/swarm-cronjob Restart=always #Environment=TZ=Europe/Paris [Install] WantedBy=multi-user.target Change the user, group, and other required startup values following your needs. Enable and start swarm-cronjob at boot: sudo systemctl enable swarm-cronjob sudo systemctl start swarm-cronjob To view logs: journalctl -fu swarm-cronjob.service","title":"Using systemd"},{"location":"usage/cli/","text":"Command Line \u00b6 Usage \u00b6 swarm-cronjob [ options ] Options \u00b6 $ swarm-cronjob --help Usage: swarm-cronjob Create jobs on a time-based schedule on Swarm. More info: https://github.com/crazy-max/swarm-cronjob Flags: --help Show context-sensitive help. --version --log-level=\"info\" Set log level ($LOG_LEVEL). --log-json Enable JSON logging output ($LOG_JSON). Environment variables \u00b6 Following environment variables can be used in place: Name Default Description LOG_LEVEL info Log level output LOG_JSON false Enable JSON logging output","title":"Command line"},{"location":"usage/cli/#command-line","text":"","title":"Command Line"},{"location":"usage/cli/#usage","text":"swarm-cronjob [ options ]","title":"Usage"},{"location":"usage/cli/#options","text":"$ swarm-cronjob --help Usage: swarm-cronjob Create jobs on a time-based schedule on Swarm. More info: https://github.com/crazy-max/swarm-cronjob Flags: --help Show context-sensitive help. --version --log-level=\"info\" Set log level ($LOG_LEVEL). --log-json Enable JSON logging output ($LOG_JSON).","title":"Options"},{"location":"usage/cli/#environment-variables","text":"Following environment variables can be used in place: Name Default Description LOG_LEVEL info Log level output LOG_JSON false Enable JSON logging output","title":"Environment variables"},{"location":"usage/docker-labels/","text":"Docker labels \u00b6 You can configure your service using swarm-cronjob through Docker labels: Name Default Description swarm.cronjob.enable Set to true to enable the cronjob. required swarm.cronjob.schedule CRON expression format to use. required swarm.cronjob.skip-running false Do not start a job if the service is currently running. swarm.cronjob.replicas 1 Number of replicas to set on schedule in replicated mode. swarm.cronjob.registry-auth false Send registry authentication details to Swarm agents. swarm.cronjob.query-registry Indicates whether the service update requires contacting a registry","title":"Docker labels"},{"location":"usage/docker-labels/#docker-labels","text":"You can configure your service using swarm-cronjob through Docker labels: Name Default Description swarm.cronjob.enable Set to true to enable the cronjob. required swarm.cronjob.schedule CRON expression format to use. required swarm.cronjob.skip-running false Do not start a job if the service is currently running. swarm.cronjob.replicas 1 Number of replicas to set on schedule in replicated mode. swarm.cronjob.registry-auth false Send registry authentication details to Swarm agents. swarm.cronjob.query-registry Indicates whether the service update requires contacting a registry","title":"Docker labels"},{"location":"usage/get-started/","text":"Get started \u00b6 Warning Before starting, you must have a swarm-cronjob instance up and running using docker or an available binary for your platform. When swarm-cronjob is ready, create a new stack to be scheduled like this one: version : \"3.2\" services : test : image : busybox command : date deploy : mode : replicated replicas : 0 labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=* * * * *\" - \"swarm.cronjob.skip-running=false\" restart_policy : condition : none You can include any configuration as long as you abide with the following conditions: Set command to run the task command Set mode to replicated (default) Set replicas to 0 to avoid running task as soon as the service is deployed Set restart_policy.condition to none . This is needed for a cronjob, otherwise the task will restart automatically Add Docker labels to tell swarm-cronjob that your service is a cronjob Once ready, deploy your scheduled stack on the swarm cluster: docker stack deploy -c date.yml date Logs $ docker service logs swarm_cronjob_app swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:04:37 UTC INF Starting swarm-cronjob v1.2.0 swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:04:37 UTC INF Add cronjob with schedule * * * * * service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:05:00 UTC INF Start job last_status=n/a service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:06:00 UTC INF Start job last_status=n/a service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:07:00 UTC INF Start job last_status=n/a service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:08:00 UTC INF Start job last_status=n/a service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:09:00 UTC INF Start job last_status=n/a service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:10:00 UTC INF Start job last_status=n/a service=date_test $ docker service logs date_test date_test.1.o1d5mn4gjff3@default | Thu Dec 13 20:11:01 UTC 2018 date_test.1.5askx244las2@default | Thu Dec 13 20:09:00 UTC 2018 date_test.1.4lz5ez2waekk@default | Thu Dec 13 20:12:00 UTC 2018 date_test.1.135qzpxd1ui3@default | Thu Dec 13 20:13:01 UTC 2018 date_test.1.hngject056n3@default | Thu Dec 13 20:10:00 UTC 2018 You can also use global mode services with swarm-cronjob. A typical use-case would be to remove unused data on your nodes using docker system prune command periodically. To do so, create a new global stack: version : \"3.2\" services : prune-nodes : image : docker command : [ \"docker\" , \"system\" , \"prune\" , \"-f\" ] volumes : - \"/var/run/docker.sock:/var/run/docker.sock\" deploy : mode : global labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=0 */5 * * * *\" - \"swarm.cronjob.skip-running=false\" restart_policy : condition : none Same conditions have to be applied as replicated mode excepted: Set mode to global Remove replicas field as this is only used with replicated mode Once ready, deploy your global cron stack on the swarm cluster: docker stack deploy -c global.yml global","title":"Get started"},{"location":"usage/get-started/#get-started","text":"Warning Before starting, you must have a swarm-cronjob instance up and running using docker or an available binary for your platform. When swarm-cronjob is ready, create a new stack to be scheduled like this one: version : \"3.2\" services : test : image : busybox command : date deploy : mode : replicated replicas : 0 labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=* * * * *\" - \"swarm.cronjob.skip-running=false\" restart_policy : condition : none You can include any configuration as long as you abide with the following conditions: Set command to run the task command Set mode to replicated (default) Set replicas to 0 to avoid running task as soon as the service is deployed Set restart_policy.condition to none . This is needed for a cronjob, otherwise the task will restart automatically Add Docker labels to tell swarm-cronjob that your service is a cronjob Once ready, deploy your scheduled stack on the swarm cluster: docker stack deploy -c date.yml date Logs $ docker service logs swarm_cronjob_app swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:04:37 UTC INF Starting swarm-cronjob v1.2.0 swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:04:37 UTC INF Add cronjob with schedule * * * * * service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:05:00 UTC INF Start job last_status=n/a service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:06:00 UTC INF Start job last_status=n/a service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:07:00 UTC INF Start job last_status=n/a service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:08:00 UTC INF Start job last_status=n/a service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:09:00 UTC INF Start job last_status=n/a service=date_test swarm_cronjob_app.1.nvsjbhdhiagl@default | Thu, 13 Dec 2018 20:10:00 UTC INF Start job last_status=n/a service=date_test $ docker service logs date_test date_test.1.o1d5mn4gjff3@default | Thu Dec 13 20:11:01 UTC 2018 date_test.1.5askx244las2@default | Thu Dec 13 20:09:00 UTC 2018 date_test.1.4lz5ez2waekk@default | Thu Dec 13 20:12:00 UTC 2018 date_test.1.135qzpxd1ui3@default | Thu Dec 13 20:13:01 UTC 2018 date_test.1.hngject056n3@default | Thu Dec 13 20:10:00 UTC 2018 You can also use global mode services with swarm-cronjob. A typical use-case would be to remove unused data on your nodes using docker system prune command periodically. To do so, create a new global stack: version : \"3.2\" services : prune-nodes : image : docker command : [ \"docker\" , \"system\" , \"prune\" , \"-f\" ] volumes : - \"/var/run/docker.sock:/var/run/docker.sock\" deploy : mode : global labels : - \"swarm.cronjob.enable=true\" - \"swarm.cronjob.schedule=0 */5 * * * *\" - \"swarm.cronjob.skip-running=false\" restart_policy : condition : none Same conditions have to be applied as replicated mode excepted: Set mode to global Remove replicas field as this is only used with replicated mode Once ready, deploy your global cron stack on the swarm cluster: docker stack deploy -c global.yml global","title":"Get started"}]}